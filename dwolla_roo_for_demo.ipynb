{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following steps to complete this are: \n",
    "1. Read in data (questions and answers) \n",
    "2. Preprocess data, remove stop words, tokenize ect. \n",
    "3. Train word2vec model; create list of question sentences and response sentences \n",
    "4. Preprocess user input, vectorize user input, calculate cosine distance (measures the angle between two vectors as a measure of similarity)... we could also use euclidean distance and compare which is better. \n",
    "5. Handle situation if the topic is not in the topic trained but asking user to rephrase?\n",
    "6. Sort similarity and return top questions and score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os, sys\n",
    "import string\n",
    "import pandas as pd \n",
    "import spacy \n",
    "import numpy as np\n",
    "from nltk import *\n",
    "import operator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.CR_response == 1].message\n",
    "responses = df[df.CR_response == 1].message\n",
    "df_responses = pd.Series(responses).to_frame()\n",
    "\n",
    "df_responses.to_csv('responses_dirty.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We all...\\n124      I was trying to set up my account per my landlord's request and the system has locked me out and...\\n125      Hi, how do I disable receiving an email notification when a TC message is received?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "q = df[df.parent_id.isna()].message\n",
    "\n",
    "question_df = pd.DataFrame(q)\n",
    "question_df\n",
    "question_df.to_csv('questions_dirty.txt')\n",
    "feedback_string=question_df.message.to_string()\n",
    "sentences = tokenize.sent_tokenize(feedback_string)\n",
    "filtered_sent = [i for i in sentences if '?' in i]\n",
    "filtered_sent[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystring =  feedback_string \n",
    "keyword = '?'\n",
    "befor_keyowrd, keyword, after_keyword = mystring.partition(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWOLLA ROO: Hi! My name is dwolla roo! I will do my best to assist in any queries you might have about dwolla\n",
      "hi\n",
      "DWOLLA ROO: Hello, How can i help?\n",
      "withdraw\n",
      "DWOLLA ROO: click on the automatic withdraw toggle button:here you can enter a start date of withdraw, frequency and the destination account.\n"
     ]
    }
   ],
   "source": [
    "f = open('dwolla_temp.csv','r', errors = 'ignore')\n",
    "raw = f.read()\n",
    "raw = raw.lower()\n",
    "\n",
    "sent_tokens = sent_tokenize(raw) # converts to list of sentences \n",
    "word_tokens = word_tokenize(raw) # converts to list of words\n",
    "\n",
    "\n",
    "lemmer = stem.WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"Good day, How may I help you?\", \"Hello, How can i help?\", \"hello\", \"I am glad! You are talking to me.\"]\n",
    "\n",
    "\n",
    "\n",
    " # Checking for greetings\n",
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)\n",
    "\n",
    "\n",
    "# Generating response\n",
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response\n",
    "\n",
    "\n",
    "flag = True\n",
    "print(\"DWOLLA ROO: Hi! My name is dwolla roo! I will do my best to assist in any queries you might have about dwolla\") \n",
    "while(flag == True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!= 'bye'):\n",
    "        if(user_response =='thanks' or user_response =='thank you' ):\n",
    "            flag=False\n",
    "            print(\"DWOLLA ROO: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"DWOLLA ROO: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"DWOLLA ROO: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"DWOLLA ROO: Bye! take care..\")    \n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
